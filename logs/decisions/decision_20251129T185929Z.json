{
  "date": "2025-11-30",
  "board": {
    "date": "2025-11-30",
    "inputs": {
      "notes": "Client reduced budget mid-month and wants recommendations to maximize conversions."
    },
    "analytics": {
      "campaigns": [
        {
          "campaign_id": "leadgen_oct",
          "name": "LeadGen Oct",
          "channel": "google",
          "daily_spend": 10.0,
          "cpa": 30.0,
          "target_cpa": 15.0,
          "conversions_last_7d": 3,
          "trend": "down"
        }
      ]
    }
  },
  "insights": {
    "campaign_insights": [
      {
        "campaign_id": "leadgen_oct",
        "recommendation": "investigate_creatives",
        "confidence": 0.6
      }
    ],
    "risks": [
      {
        "campaign_id": "leadgen_oct",
        "issue": "high_cpa",
        "urgency": 8,
        "note": "CPA 30.0 > target 15.0"
      }
    ]
  },
  "plan": [],
  "results": {
    "results": []
  },
  "llm_raw": {
    "text": "sdk_http_response=HttpResponse(\n  headers=<dict len=11>\n) candidates=[Candidate(\n  content=Content(\n    role='model'\n  ),\n  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n  index=0\n)] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='kUIrabPgFISGqfkPnI_EmQs' usage_metadata=GenerateContentResponseUsageMetadata(\n  prompt_token_count=229,\n  prompt_tokens_details=[\n    ModalityTokenCount(\n      modality=<MediaModality.TEXT: 'TEXT'>,\n      token_count=229\n    ),\n  ],\n  thoughts_token_count=1499,\n  total_token_count=1728\n) automatic_function_calling_history=[] parsed=None",
    "meta": {
      "model": "gemini-2.5-flash",
      "source": "gemini",
      "api_key_masked": "...8kHKEQ"
    },
    "raw_str": "sdk_http_response=HttpResponse(\n  headers=<dict len=11>\n) candidates=[Candidate(\n  content=Content(\n    role='model'\n  ),\n  finish_reason=<FinishReason.MAX_TOKENS: 'MAX_TOKENS'>,\n  index=0\n)] create_time=None model_version='gemini-2.5-flash' prompt_feedback=None response_id='kUIrabPgFISGqfkPnI_EmQs' usage_metadata=GenerateContentResponseUsageMetadata(\n  prompt_token_count=229,\n  prompt_tokens_details=[\n    ModalityTokenCount(\n      modality=<MediaModality.TEXT: 'TEXT'>,\n      token_count=229\n    ),\n  ],\n  thoughts_token_count=1499,\n  total_token_count=1728\n) automatic_function_calling_history=[] parsed=None"
  }
}